# JD商品评论爬虫项目
## 一、项目概述
本项目是一个用于爬取京东商品评论数据的Python爬虫程序。它能够根据配置文件中的商品链接，获取商品的评论信息，并将其保存为CSV文件，方便后续进行数据分析、情感研究等工作。
京东商品的评论显示收到平台限制，无法获取全部评论数据，只能获取部分评论数据。具体规则为每种筛选方式，最多爬取100页数据。为了爬取更多数据，可以遍历所有评论排序方式（如全部商品、晒图、追评、好评等），获取更多数据，但是此方法可能会产生大量重复数据，建议在爬取后对数据进行去重操作。

## 二、项目特点
- **高度可配置化**：通过修改配置文件`config.py`，可以灵活设置是否遍历评论排序方式，以及添加或修改要爬取的商品URL。
- **摆脱pandas依赖**：采用`with open`结合`csv`模块的方式写入数据，减少了对第三方库的依赖，降低了项目的复杂性。
- **模块化设计**：将请求处理、数据获取等功能封装在不同模块中，提高了代码的可读性和可维护性。

## 三、项目结构
```
JD_Comment_Spider/
│
├── data/                # 用于存储爬取的数据
│   ├── output/          # 存储爬取结果的CSV文件
│   └── url.xlsx         # 存储商品URL的Excel文件（原项目保留，现可忽略，URL在config.py中配置）
│
├── logs/                # 用于存储日志文件
│   └── spider.log       # 日志文件，记录爬虫运行过程中的关键信息
│
├── utils/               # 存放工具函数和类
│   ├── __init__.py      # 初始化文件，使Python将该目录视为一个Python包
│   └── request_utils.py # 封装请求相关的工具函数，如发送请求、处理JSON数据
│
├── main.py              # 主程序入口，负责调用各个模块的功能，控制爬虫的运行流程
├── config.py            # 配置文件，存储常量和配置信息，如请求头、URL格式、是否遍历排序方式、商品URL列表等
├── README.md            # 当前项目说明文档，介绍项目的功能、使用方法、依赖库等信息
└── requirements.txt     # 项目依赖的Python库列表，方便用户安装项目所需的依赖
```

## 四、使用方法
### （一）配置文件修改
1. **商品URL配置**：打开`config.py`文件，找到`PRODUCT_URLS`列表。在列表中添加或修改要爬取的京东商品链接。例如：
```python
PRODUCT_IDS = [
    "123456",  # 替换为实际的商品id
    "789012"   # 可以添加多个商品id
]
```
2. **是否遍历评论排序方式配置**：在`config.py`文件中，找到`TRAVERSE_SORTING`配置项。如果希望遍历所有评论排序方式（如全部商品、晒图、追评、好评等），将其设置为`True`；如果只希望按全部评论排序，设置为`False`。例如：
```python
TRAVERSE_SORTING = True  # 开启遍历评论排序方式
# TRAVERSE_SORTING = False  # 只爬取全部评论筛选方式下的数据
```

3. **是否去重配置**：在`config.py`文件中，找到`DEDUPLICATION`配置项，如果希望对爬取的数据进行去重处理，将其设置为`True`；如果希望保留重复数据，设置为`False`。例如：
```python
DEDUPLICATION = True # 开启去重功能
```

### （二）安装依赖库
打开命令行工具，进入项目所在目录，执行以下命令安装项目所需的依赖库：
```bash
pip install -r requirements.txt
```
依赖库主要包括：
- **requests**：用于发送HTTP请求，获取网页数据。
- **fake - useragent**：用于生成随机的用户代理，模拟不同的浏览器访问，避免被网站识别为爬虫。

### （三）运行爬虫
在命令行中确保当前目录为项目根目录，执行以下命令启动爬虫：
```bash
python main.py
```
运行过程中，程序会在命令行输出爬取进度信息，如当前正在爬取的商品、排序方式、页码以及已爬取的评论数量等。同时，爬取的评论数据会保存到`data/output`目录下，每个商品对应一个CSV文件，文件名包含商品ID信息，如果开启了去重功能，则程序会在爬取完成后对数据进行去重操作，并生成一个去重后的新文件。

## 五、注意事项
### （一）遵守网站规则
请遵守京东平台的使用规则和法律法规，不要过度或恶意爬取数据，避免对网站造成不必要的负担或侵犯他人权益。本项目仅供学习和研究使用，未经授权请勿用于商业用途。

### （二）网络及反爬机制
1. 网络状况会影响爬虫的运行效果。请确保网络连接稳定，否则可能会出现请求失败、数据获取不完整等问题。
2. 京东可能会采取反爬措施，如限制访问频率、检测异常请求等。本项目通过设置随机的用户代理和合理的请求间隔时间（0.5 - 2秒）来尽量避免被反爬机制拦截，但仍不能完全保证不被限制。如果遇到频繁请求失败的情况，建议适当调整请求间隔时间或暂停爬取操作。

### （三）数据处理与存储
1. 爬取的数据仅包含评论相关的基本信息，如用户ID、评论内容、购买时间等。如果需要获取更多信息，可能需要进一步修改代码逻辑。
2. 由于京东商品评论数量可能较多，爬取过程可能会花费较长时间。

## 六、免责声明
本项目仅供学习参考，请勿用于非法用途。任何使用本代码或相关资源的行为，包括但不限于未经授权使用、复制、修改、传播等，均属于违法行为，使用者需自行承担法律后果。